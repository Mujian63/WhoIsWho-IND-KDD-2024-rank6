{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "86903ca9-bd4f-4914-9e15-24d6b2dc2c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold,GroupKFold\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "import re\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import os\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import polars as pl\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import json\n",
    "import joblib\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d735d3a1-2271-4d0f-81a2-28e31312118c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../IND-WhoIsWho/pid_to_info_all.json', 'r') as file:\n",
    "    pid = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2f32479-fbeb-403f-b976-008e2eb67420",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train = pd.read_feather('data/train.feather')\n",
    "valid = pd.read_feather('data/valid.feather')\n",
    "test = pd.read_feather('data/test.feather')\n",
    "\n",
    "train['dataset_mode'] = 0\n",
    "valid['dataset_mode'] = 1\n",
    "test['dataset_mode'] = 2\n",
    "\n",
    "data = pd.concat([train,valid,test]).reset_index(drop = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f348dc0c-5d7e-48c0-a16e-57da1ddad7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof = pd.read_feather('oof2/cat_oof.feather')\n",
    "del df_oof['label_prob']\n",
    "\n",
    "temp =  pd.read_feather('oof2/lgb_oof.feather')\n",
    "df_oof['lgb_prob'] = temp['label_prob']\n",
    "\n",
    "temp =  pd.read_feather('oof2/xgb_oof.feather')\n",
    "df_oof['xgb_prob'] = temp['label_prob']\n",
    "\n",
    "\n",
    "temp =  pd.read_feather('oof2/cat_oof.feather')\n",
    "df_oof['cat_prob'] = temp['label_prob']\n",
    "\n",
    "\n",
    "temp =  pd.read_feather('oof2/feat_select_lgb_oof.feather')\n",
    "df_oof['lgb_prob_2'] = temp['label_prob']\n",
    "\n",
    "temp =  pd.read_feather('oof2/feat_select_xgb_oof.feather')\n",
    "df_oof['xgb_prob_2'] = temp['label_prob']\n",
    "\n",
    "temp =  pd.read_feather('oof2/feat_select_cat_oof.feather')\n",
    "df_oof['cat_prob_2'] = temp['label_prob']\n",
    "\n",
    "\n",
    "temp =  pd.read_feather('oof2/gnn_oof.feather')\n",
    "df_oof['gnn_prob'] = temp['label_prob']\n",
    "\n",
    "\n",
    "prediction = pd.read_feather('oof2/cat_prediction.feather')\n",
    "del prediction['label_prob']\n",
    "\n",
    "temp =  pd.read_feather('oof2/lgb_prediction.feather')\n",
    "prediction['lgb_prob'] = temp['label_prob']\n",
    "\n",
    "temp =  pd.read_feather('oof2/xgb_prediction.feather')\n",
    "prediction['xgb_prob'] = temp['label_prob']\n",
    "\n",
    "\n",
    "temp =  pd.read_feather('oof2/cat_prediction.feather')\n",
    "prediction['cat_prob'] = temp['label_prob']\n",
    "\n",
    "\n",
    "temp =  pd.read_feather('oof2/feat_select_lgb_prediction.feather')\n",
    "prediction['lgb_prob_2'] = temp['label_prob']\n",
    "\n",
    "temp =  pd.read_feather('oof2/feat_select_xgb_prediction.feather')\n",
    "prediction['xgb_prob_2'] = temp['label_prob']\n",
    "\n",
    "temp =  pd.read_feather('oof2/feat_select_cat_prediction.feather')\n",
    "prediction['cat_prob_2'] = temp['label_prob']\n",
    "\n",
    "\n",
    "temp =  pd.read_feather('oof2/gnn_prediction.feather')\n",
    "prediction['gnn_prob'] = temp['label_prob']\n",
    "\n",
    "\n",
    "\n",
    "temp = pd.concat([df_oof,prediction]).reset_index(drop = True)\n",
    "del temp['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5aaf235-b93c-4c22-9aa2-86c554e7b35e",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = joblib.load('edges_all.pkl')\n",
    "data['id'] = data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a4880-2e98-4c09-9b3a-65f928f130eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "edges_0 = dict(edges.groupby(0)[1].agg(list))\n",
    "edges_1 = dict(edges.groupby(1)[0].agg(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a78ebd2-973e-44c6-ae4a-f4b82c91d61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [3,3,1,1,1,1,8]\n",
    "#weight = [0,0,0,0,0,0,1]\n",
    "weight = np.array(weight) / sum(weight)\n",
    "df_oof['label_prob'] = 0\n",
    "prediction['label_prob'] = 0\n",
    "\n",
    "ff = [ 'lgb_prob', 'xgb_prob', 'cat_prob','lgb_prob_2', 'xgb_prob_2', 'cat_prob_2','gnn_prob']\n",
    "for i in range(len(ff)):\n",
    "    df_oof['label_prob'] += df_oof[ff[i]] * weight[i]\n",
    "    prediction['label_prob'] += prediction[ff[i]] * weight[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b8b7b8-3e85-47c0-9c32-3bbae53df6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_oof['id'] = data['id'].values[:df_oof.shape[0]]\n",
    "prediction['id'] = data['id'].values[df_oof.shape[0]:]\n",
    "t_dict = dict(df_oof[['id','label_prob']].values)\n",
    "t_dict.update(dict(prediction[['id','label_prob']].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa35f9e7-9ca6-45fe-81d3-639e28cc2457",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_oof['neighbour_0'] = df_oof['id'].map(edges_0)\n",
    "df_oof.loc[df_oof['neighbour_0'].isna(),'neighbour_0'] = df_oof.loc[df_oof['neighbour_0'].isna(),'id'].apply(lambda x:[x])\n",
    "df_oof['neighbour_1'] = df_oof['id'].map(edges_1)\n",
    "df_oof.loc[df_oof['neighbour_1'].isna(),'neighbour_1'] = df_oof.loc[df_oof['neighbour_1'].isna(),'id'].apply(lambda x:[x])\n",
    "df_oof['neighbour_1'] = df_oof['neighbour_0'] + df_oof['neighbour_1']\n",
    "df_oof['neighbour_1'] = df_oof['neighbour_1'].apply(lambda x:list(set(x)))\n",
    "\n",
    "df_oof['neighbour_1'] = df_oof['neighbour_1'].apply(lambda x:[t_dict[f] for f in x])\n",
    "df_oof['neighbour_1'] = df_oof['neighbour_1'].apply(lambda x:np.mean(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582b1397-a8e8-41e8-b405-4b40c79ac6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction['neighbour_0'] = prediction['id'].map(edges_0)\n",
    "prediction.loc[prediction['neighbour_0'].isna(),'neighbour_0'] = prediction.loc[prediction['neighbour_0'].isna(),'id'].apply(lambda x:[x])\n",
    "prediction['neighbour_1'] = prediction['id'].map(edges_1)\n",
    "prediction.loc[prediction['neighbour_1'].isna(),'neighbour_1'] = prediction.loc[prediction['neighbour_1'].isna(),'id'].apply(lambda x:[x])\n",
    "prediction['neighbour_1'] = prediction['neighbour_0'] + prediction['neighbour_1']\n",
    "prediction['neighbour_1'] = prediction['neighbour_1'].apply(lambda x:list(set(x)))\n",
    "\n",
    "prediction['neighbour_1'] = prediction['neighbour_1'].apply(lambda x:[t_dict[f] for f in x])\n",
    "prediction['neighbour_1'] = prediction['neighbour_1'].apply(lambda x:np.mean(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce784a6-7cb6-4c26-9c3b-a592817b48f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction['label_prob_post'] = prediction['neighbour_1']*0.4 + prediction['label_prob']*0.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2d9e8-a769-4896-b193-5ff87106c017",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"IND-test-public/ind_test_author_submit.json\") as f:\n",
    "    submission=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90ff679-957e-41e0-ae97-ac432f193739",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_preds = prediction.loc[df_test['dataset_mode'] == 2,'label_prob_post'].to_list()\n",
    "cnt=0\n",
    "for id,names in submission.items():\n",
    "    for name in names:\n",
    "        submission[id][name]=test_preds[cnt]\n",
    "        cnt+=1\n",
    "with open('sub/B_baseline_608_3.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(submission, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
